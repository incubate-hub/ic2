{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6406fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 09:59:58.899213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-22 09:59:58.899241: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-22 09:59:59.564297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 09:59:59.564388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 09:59:59.564399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-22 10:00:01.066513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-03-22 10:00:01.066556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (manas-MacBookPro): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the vectorize_program function\n",
    "def vectorize_program(program):\n",
    "    # Tokenize and vectorize the program\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts([program])\n",
    "    sequence = tokenizer.texts_to_sequences([program])[0]\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([sequence])\n",
    "    vectorized_program = tf.one_hot(padded_sequence, depth=len(tokenizer.word_index)+1)\n",
    "\n",
    "    # Pad the program vector with zeros along the second dimension\n",
    "    max_len = max(len(sequence), 1)\n",
    "    padded_program = tf.keras.preprocessing.sequence.pad_sequences(vectorized_program, maxlen=max_len, padding='post')\n",
    "    vectorized_program_2d = np.reshape(padded_program, (-1, padded_program.shape[-1]))\n",
    "\n",
    "    return vectorized_program_2d\n",
    "\n",
    "# Define the list of filenames and their labels\n",
    "filenames = ['code1.py', 'code2.py', 'code3.py', 'code4.py', 'code5.py', 'code6.py', 'code7.py', 'code8.py', 'code9.py', 'code10.py', 'code11.py', 'code12.py', 'code13.py', 'code14.py', 'code15.py', 'code16.py', 'code17.py', 'code18.py', 'code19.py', 'code20.py']\n",
    "labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Initialize lists to store the true labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Loop over the filenames\n",
    "for filename, label in zip(filenames, labels):\n",
    "    # Read the program from the file\n",
    "    with open(filename, 'r') as file:\n",
    "        program = file.read()\n",
    "\n",
    "    # Vectorize the program\n",
    "    vectorized_program = vectorize_program(program)\n",
    "\n",
    "    # Append the true label to the list\n",
    "    true_labels.append(label)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_size = int(0.8 * vectorized_program.shape[0])\n",
    "    train_data = vectorized_program[:train_size]\n",
    "    test_data = vectorized_program[train_size:]\n",
    "\n",
    "    # Fit the IsolationForest model on the training set\n",
    "    model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Use the trained model to predict anomalies in the test set\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    # Append the prediction to the list\n",
    "    predictions.append(int(sum(pred == -1) > 0))\n",
    "\n",
    "# Compute the accuracy of the predictions\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43ead4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
